{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes AUTOML with TPOT, Local Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.0\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Command to install the below commands\n",
    "# !pip3 install tpot\n",
    "# !pip3 install torch\n",
    "!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tpot\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_file = './Files/diabetes_train_column_list.txt'\n",
    "train_file = './Files/diabetes_train.csv'\n",
    "validation_file = './Files/diabetes_validation.csv'\n",
    "entire_dataset = './Files/diabetes_train_all_normalized.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Training, Validation files and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes_class',\n",
       " 'preg_count',\n",
       " 'glucose_concentration',\n",
       " 'diastolic_bp',\n",
       " 'triceps_skin_fold_thickness',\n",
       " 'two_hr_serum_insulin',\n",
       " 'bmi',\n",
       " 'diabetes_pedi',\n",
       " 'age']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(column_list_file,'r') as f:\n",
    "    columns = f.read().split(',')\n",
    "    \n",
    "columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = pd.read_csv(train_file, names=columns)\n",
    "df_validation = pd.read_csv(validation_file,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flatten target to 1D array with ravel()\n",
    "X_train = df_train.iloc[:,1:]\n",
    "y_train = df_train.iloc[:,0].ravel()\n",
    "\n",
    "X_valid = df_validation.iloc[:,1:]\n",
    "y_valid = df_validation.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b11eb497cf4c2295c1070a82d9543a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=600.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8993596400138456\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.9011941848390446\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.905019037729318\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.905019037729318\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.905019037729318\n",
      "\n",
      "Best pipeline: XGBClassifier(input_matrix, learning_rate=1.0, max_depth=4, min_child_weight=14, n_estimators=100, nthread=1, subsample=0.9500000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(generations=5, verbosity=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tpot\n",
    "auto_ml = tpot.TPOTClassifier(generations=5,population_size=100,\n",
    "         offspring_size=None,mutation_rate=0.9,crossover_rate=0.1,\n",
    "         scoring=None,cv=5,subsample=1.0,n_jobs=1,\n",
    "         max_time_mins=None,max_eval_time_mins=5,random_state=None,\n",
    "         config_dict=None,template=None,warm_start=False,\n",
    "         memory=None,use_dask=False,periodic_checkpoint_folder=None,\n",
    "         early_stop=None,verbosity=2,\n",
    "         disable_update_check=False)\n",
    "\n",
    "auto_ml.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=600.0, style=ProgressStyle(de…\n",
    "\n",
    "# Generation 1 - Current best internal CV score: 0.8994115610938043\n",
    "\n",
    "# Generation 2 - Current best internal CV score: 0.8994115610938043\n",
    "\n",
    "# Generation 3 - Current best internal CV score: 0.9012634129456559\n",
    "\n",
    "# Generation 4 - Current best internal CV score: 0.9031152647975077\n",
    "\n",
    "# Generation 5 - Current best internal CV score: 0.9049844236760125\n",
    "\n",
    "# Best pipeline: RandomForestClassifier(SelectFwe(input_matrix, alpha=0.041), bootstrap=False, criterion=entropy, max_features=0.4, min_samples_leaf=4, min_samples_split=5, n_estimators=100)\n",
    "# TPOTClassifier(generations=5, verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(bootstrap=False, criterion='entropy', max_features=0.4, min_samples_leaf=4, min_samples_split=5, n_estimators=100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf_results = clf.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Diabetic       0.85      0.85      0.85        79\n",
      "      Normal       0.92      0.92      0.92       152\n",
      "\n",
      "    accuracy                           0.90       231\n",
      "   macro avg       0.88      0.88      0.88       231\n",
      "weighted avg       0.90      0.90      0.90       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(\n",
    "    df_validation['diabetes_class'],\n",
    "    clf_results,\n",
    "    labels=[1,0],\n",
    "    target_names=['Diabetic','Normal']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predicted to df_train and check confusion matrix\n",
    "# check logloss training and validation error\n",
    "# if everything is looks good on the test set, then re-train the model on entire dataset then serialize it using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9212c32c5dd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary:logistic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = xgb.XGBClassifier(objective=\"binary:logistic\")\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train,\n",
    "               y_train, \n",
    "               eval_set = [(X_train, y_train), (X_valid, y_valid)], \n",
    "               eval_metric=['logloss'],\n",
    "               early_stopping_rounds= 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit(X_train,\n",
    "               y_train, \n",
    "               eval_set = [(X_train, y_train), (X_valid, y_valid)], \n",
    "               eval_metric=['logloss'],\n",
    "               early_stopping_rounds= 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
